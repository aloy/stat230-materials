{
  "hash": "13751771c7fe903aa0fae8d662c7b6a5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Polynomial Regression\"\nformat: \n  html:\n    toc: true\nengine: knitr\neditor: source\neditor_options: \n  chunk_output_type: console\n---\n\n\n\n\n## Loading data\n\nTo load the wildfires data set, run the following code chunk:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwildfires <- read.csv(\"https://aloy.github.io/stat230-materials/data/wildfires.csv\")\n```\n:::\n\n\n\n\n## Fitting a polynomial regression model\n\nTo fit a polynomial regression model we still use the `lm()` command, but we expand our formula to include polynomial terms. To include polynomial terms in a regression model, we need to use the `I()` function to indicate that we want to calculate a polynomial term. For example, to fit the quadratic model we have already discussed in class, we use the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nquadratic_lm <- lm(Acres ~ Year + I(Year^2), data = wildfires)\n```\n:::\n\n\nOnce you have your fitted model, we can explore it like we have with simple linear regression models.\n\n\n\n## Exploring a cubic model\n\nLet's fit a cubic model to the wildfires data set. The cubic model has the form \n$$\\mu \\lbrace y | x \\rbrace = \\beta_0 + \\beta_1 x + \\beta_2x^2 + \\beta_3x^3.$$\nUse the `lm()` command to fit the cubic model where `Year` is used to predict `Acres`.\n\n:::{.callout-tip collapse=\"true\"}\n## Solution\n\n::: {.cell}\n\n```{.r .cell-code}\ncubic_lm <- lm(Acres ~ Year + I(Year^2) + I(Year^3), data = wildfires)\n```\n:::\n\n:::\n\nTo plot the fitted cubic model, you can use the `gf_point()` and `gf_lm()` functions from the `ggformula` package. The following code will create a scatter plot of the data and add the fitted cubic regression line:\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ngf_point(Acres ~ Year, data = wildfires, xlab = \"Year\", ylab = \"Acres burned\") |>\n  gf_lm(formula = y ~ poly(x, 3), linewidth = .5)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nWarning: Using the `size` aesthetic with geom_line was deprecated in ggplot2 3.4.0.\nâ„¹ Please use the `linewidth` aesthetic instead.\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](07-sol-mlr-polynomial_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=480}\n:::\n:::\n\n\n:::{.callout-note}\nIn the `gf_lm()` layer we use the `poly(x, 3)` function to specify that we want to fit a cubic polynomial. You can use `poly()` to fit polynomials of any degree by changing the second argument, and you can also use this function within the `lm()` function to fit polynomial regression models if you'd like.\n:::\n\nDoes the cubic model appear to be necessary? Use the `summary()` function to explore the fitted model and run a hypothesis test for the cubic term. What do you conclude?\n\n:::{.callout-tip collapse=\"true\"}\n## Solution\nThe t-test for $H_0: \\beta_3 = 0$ vs. $H_a: \\beta_3 \\neq 0$ shows that this term is not statistically significant, so we do not have sufficient evidence to conclude that the cubic term is necessary in our model.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(cubic_lm)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Acres ~ Year + I(Year^2) + I(Year^3), data = wildfires)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-4042634 -1462388  -220730  1720630  3904566 \n\nCoefficients:\n              Estimate Std. Error t value Pr(>|t|)\n(Intercept)  3.320e+11  5.078e+11   0.654    0.516\nYear        -4.928e+08  7.660e+08  -0.643    0.523\nI(Year^2)    2.437e+05  3.851e+05   0.633    0.530\nI(Year^3)   -4.015e+01  6.454e+01  -0.622    0.536\n\nResidual standard error: 1920000 on 55 degrees of freedom\nMultiple R-squared:  0.4247,\tAdjusted R-squared:  0.3933 \nF-statistic: 13.54 on 3 and 55 DF,  p-value: 9.971e-07\n```\n\n\n:::\n:::\n\n:::\n\nWhat degrees of freedom did R for the t-distribution used to calculate the p-value for the test of the cubic term?\n\n:::{.callout-tip collapse=\"true\"}\n### Solution\nThe test uses df = n - (3 + 1) = 55.\n:::\n\nDo you notice anything curious about the inferential results for the linear and quadratic terms?\n\n:::{.callout-tip collapse=\"true\"}\n## Solution\nYes! All of the polynomial terms are not statistically significant, even though the linear and quadratic terms were in the previous model.\n:::\n\nThe issue here is that the polynomial terms for year are highly correlated with each other (i.e., year, year$^2$, and year$^3$ are correlated). This can lead to numerical instability and make it difficult to interpret the coefficients. This is a situation called **multicollinearity**. We'll talk more about this later. One way to remedy this issue in polynomial regression is to use orthogonal polynomials, which are uncorrelated with each other. \n\n## An alternative way to fit polynomials\n\nTo fit polynomial model with uncorrelated polynomial terms use the `poly()` function. For example, to fit a cubic model using orthogonal polynomials, we can run the following code:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncubic_lm_ortho <- lm(Acres ~ poly(Year, 3), data = wildfires)\n```\n:::\n\n\nUse the `summary()` function to explore the fitted model. What do you notice about the inferential results for the linear, quadratic, and cubic terms? How does this compare to the previous cubic model we fit? How does it compare to the quadratic model?\n\n\n:::{.callout-tip collapse=\"true\"}\n## Solution\n\nUsing an orthogonal polynomial via `poly()` results in the linear and quadratic terms being statistically significant, which is in line with what we saw in the quadratic model. The cubic term is not statistically significant, so we have no evidence that it is needed.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncubic_lm_ortho <- lm(Acres ~ poly(Year, 3), data = wildfires)\nsummary(cubic_lm_ortho)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = Acres ~ poly(Year, 3), data = wildfires)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-4042634 -1462388  -220730  1720630  3904566 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)     4641410     250012  18.565  < 2e-16 ***\npoly(Year, 3)1  9025270    1920377   4.700 1.79e-05 ***\npoly(Year, 3)2  8177004    1920377   4.258 8.11e-05 ***\npoly(Year, 3)3 -1194695    1920377  -0.622    0.536    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1920000 on 55 degrees of freedom\nMultiple R-squared:  0.4247,\tAdjusted R-squared:  0.3933 \nF-statistic: 13.54 on 3 and 55 DF,  p-value: 9.971e-07\n```\n\n\n:::\n:::\n\n\n:::\n\n:::{.calllout-note}\nThe method of constructing the polynomial terms in our regression model does not change our predictions, but it can change the inferential results for the polynomial terms.\n:::\n\n\n***\n\n## Function quick reference\n\nThe following table summarizes the functions we learned today:\n\n| Function | Purpose |\n|----|-----------|\n| `lm(formula, data)` | Fit a linear model. For polynomial regression the formula should include polynomial terms or use `poly()`. |\n| `I()` | Used to create polynomial terms in a regression model |\n| `poly(x, degree)` | Create orthogonal polynomial terms |\n\n\n",
    "supporting": [
      "07-sol-mlr-polynomial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}