{
  "hash": "1bced752cc41cb7b10500e10e159fd26",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Diagnostic Tools for Binary Logistic Regression\"\nsubtitle: \"An R Tutorial\"\nwebr:\n  packages:\n    - Sleuth3\n    - broom\n    - dplyr\n    - ggformula\n    - car\nformat: \n  live-html:\n    toc: true\neditor: source\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n\nIn this tutorial we'll explore the model fit of a binary logistic regression using R. We'll use the Framingham Heart Study data set as an example. To load the data, run the following code chunk:\n\n\n::: {.cell}\n```{webr}\nframingham <- read.csv(\"https://aloy.github.io/stat230-materials/data/framingham.csv\")\n```\n:::\n\n\n:::{.callout-note}\n## R packages\n\nI have run the following command to load the required R packages for this tutorial:\n\n```\nlibrary(dplyr)\nlibrary(broom)\nlibrary(ggformula)\nlibrary(car)\n```\n\n\n:::\n\n\nWe'll explore the same model discussed in class, which is fit below.\n\n\n::: {.cell}\n```{webr}\nheart_mod <- glm(TenYearCHD ~ age + male + totChol + sysBP, data = framingham, \nfamily = \"binomial\")\n```\n:::\n\n\nIn the next sections, you'll be guided through the creation of the various diagnostic plots discussed in class. Be sure to run each code chunk to see the resulting plots, and don't hesitate to ask me questions if things are unclear!\n\n\n## Residual plots\n\nLike in linear regression, we can construct residual plots to assess the fit of our binary logistic regression model. The interpretation of these plots is harder, however, since the response variable is binary; thus, we can't expect to see a random scatter of points around zero like we did in linear regression. To help with the interpretation, we'll explore both binned residual plots and Pearson residual plots with a LOESS smoother.\n\n### Binned residual plots\n\nTo construct a binned residual plot we follow these steps:\n\n1. Calculate response residuals\n2. Order observations either by the values of the predicted log odds/probabilities, or by quantitative predictor variable\n3. Use the ordered data to create $g$ bins of approximately equal size. (A reasonable starting point is $g = \\sqrt{n}$)\n4. Calculate average residual value in each bin\n5. Plot average residuals vs. average predicted log odds, probability, or predictor value\n\n\nLet's implement these steps in R. First, we augment (add columns to) our data set with the predicted values and response residuals:\n\n\n::: {.cell}\n```{webr}\nheart_aug <- augment(heart_mod, type.predict= \"link\", type.residuals = \"pearson\") |>\n  mutate(.resp.resid = resid(heart_mod, type= \"response\"))\n```\n:::\n\n\n:::{.callout-note}\n## Adapting the code\nTo adapt this code for your own binary logistic regression model, simply replace `heart_mod` with the name of your model object in both the `augment()` function and the `resid()` function.\n:::\n\nNext, we create the binned residual plot by following steps 2-4 outlined above:\n\n\n::: {.cell}\n```{webr}\nbinned_resids <- heart_aug |> \n  mutate(bin = ntile(heart_mod$linear.predictors, 65)) |>\n  group_by(bin) |>\n  summarize(mean_linear_pred = mean(.fitted),\n            avg_resid = mean(.resp.resid),\n            .groups = \"drop\")\n```\n:::\n\n\n:::{.callout-note}\n## Adapting the code\nTo adapt this code for your own binary logistic regression model, replace `heart_aug` with the name of your augmented data set and then replace `heart_mod$linear.predictors` with the linear predictors from your model object (by changing the model name to the left of the `$`). Additionally, you can adjust the number of bins (currently set to 65) based on your data size.\n:::\n\nFinally, we plot the binned residuals:\n\n\n::: {.cell}\n```{webr}\ngf_point(avg_resid ~ mean_linear_pred, data = binned_resids,\n         xlab = \"Predicted log odds\", ylab = \"Average response residual\") |>\n  gf_hline(yintercept = 0, linetype = 2) \n```\n:::\n\n\n\nThe above process creates a binned residual plot of the response residuals against the predicted log odds. You can also create similar plots using predicted probabilities or individual predictor variables by adjusting the code accordingly.\n\nBelow we create a binned residual plot where 65 bins were created from the `age` variable. Notice that now we need to calculate both the mean value of the predictor and the mean value of the residual.\n\n\n::: {.cell}\n```{webr}\nheart_aug |> \n  mutate(bin = ntile(age, 65)) |>  # Creating 65 bins for age\n  group_by(bin) |>\n  summarize(mean_age = mean(age),\n            avg_resid = mean(.resp.resid)) |>\n  gf_point(\n    avg_resid ~ mean_age,\n    xlab = \"Mean age in bin\", \n    ylab = \"Average response residual\"\n  ) |>\n  gf_hline(yintercept = 0, linetype = 2) \n```\n:::\n\n\n\n\n## Empirical logit\n\nTo create empirical (sample) logit plots, we need to create bins based on the values of our predictor variables and then calculate the sample logits. To reproduce the plot on the slides, we first augment the data set with the predicted probabilities (`type.predict = \"response\"` means that the `.fitted` column gives us the $\\widehat{\\pi}_i$ values for each row). Then, we can use the `mutate()` command to add columns for the bins via the `ntile()` function.\n\n\n::: {.cell}\n```{webr}\nheart_aug <- augment(heart_mod, type.predict = \"response\") |>\n  mutate(\n    age_bin = ntile(age, 50),           # Bins for age\n    totChol_bin = ntile(totChol, 50),   # Bins for totChol\n    sysBP_bin = ntile(sysBP, 50)        # Bins for sysBP\n  )\n```\n:::\n\n\n:::{.callout-note}\n## Adapting the code\nTo adapt this code for your own binary logistic regression model, simply replace `heart_mod` with the name of your model object in the `augment()` function. Then, replace `age`, `totChol`, and `sysBP` with the names of the predictor variables you wish to create bins for (or delete them if not needed).\n:::\n\nTo create the data set needed for the plot, we use our augmented data set, group it by the binned version of the response variable (age for the example below). Then we calculate the mean of the predictor (to plot as out x coordinate), the empirical probability (`emp.prob`), the empirical odds (`emp.odds`), and the empirical logit (`emp.logit`).\n\n\n::: {.cell}\n```{webr}\nemp_logit_df <- heart_aug |>\n  group_by(age_bin) |>\n  summarize(\n    midpoint = mean(age),\n    emp.prob = (sum(TenYearCHD) + 0.5) / (n() + 1),\n    emp.odds = emp.prob / (1 - emp.prob),\n    emp.logit = log(emp.odds),\n    .groups = \"drop\"\n  )\n```\n:::\n\n\n\n:::{.callout-note}\n## Adapting the code\nTo adapt this code for your own binary logistic regression model, replace `heart_aug` with the name of your augmented data set and then replace `age_bin` with the binned version of the predictor variable you wish to create the empirical logit plot for. Then, replace `age` with the name of the predictor variable you wish to calculate the midpoint for and `TenYearCHD` with the name of your binary response variable.\n:::\n\n\nFinally, we can create a plot of the empirical logit against the mean value of the predictor variable in each bin:\n\n\n::: {.cell}\n```{webr}\ngf_point(emp.logit ~ midpoint, data = emp_logit_df,\n         xlab = \"Mean age in bin\", ylab = \"Empirical logit\")\n```\n:::\n\n\n:::{.callout-note}\n## Adapting the code\nTo adapt this code for your own binary logistic regression model, replace `emp_logit_df` with the name of your empirical logit data set and then replace `midpoint` and `emp.logit` with the names of the corresponding columns in your data set (if you changed those names at all). Then, change your `xlab` to match the predictor variable you are plotting.\n:::\n\n\n## Pearson residuals\n\nTo create a Pearson residual plot with a LOESS smoother, we can use the `residualPlots()` command from the `car` Package, similar to what we did in linear regression. The only difference is that we need to specify `type = \"pearson\"` to indicate that we want to plot Pearson residuals.\n\nBelow we recreate the residual plots from the slides:\n\n\n\n::: {.cell}\n```{webr}\nresidualPlots(heart_mod, type = \"pearson\", smooth = TRUE, tests = FALSE)\n```\n:::\n\n\n\n\n\n***\n\n## Function quick reference\n\nThe following table summarizes the functions discussed above:\n\n| Function | Purpose |\n|----|-----------|\n| `augment(model, type.predict, type.residuals)` | Add predicted values and residuals to data set |\n| `residualPlots(model, type = \"pearson\", smooth = TRUE, tests = FALSE)` | Create residual plots with LOESS smoother |\n| `group_by(variable)` | Group data by variable for summarization |\n| `summarize()` | Summarize data by calculating statistics like mean, count, etc. |\n| `gf_point(y ~ x, data, xlab, ylab)` | Create scatter plot of y vs. x with labels |\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}