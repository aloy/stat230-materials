{
  "hash": "0051e2bac42466198fc362d5c1151b8d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Binary Logistic Regression in R\"\nwebr:\n  packages:\n    - Sleuth3\n    - broom\nformat: \n  live-html:\n    toc: true\neditor: source\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n## Fitting a Binary Logistic Regression Model\n\nFitting a binary logistic regression model in R is similar to fitting a linear regression model. To guide you through this process, let's revisit the Framingham Heart Study data set that we discussed in class.\n\nTo load the data, run the following code chunk:\n\n\n::: {.cell}\n```{webr}\nframingham <- read.csv(\"https://aloy.github.io/stat230-materials/data/framingham.csv\")\n```\n:::\n\n\nBinary logistic regression requires a binary response variable. In this case, we will use the `TenYearCHD` variable, which indicates whether an individual developed coronary heart disease within ten years (1 = yes, 0 = no). Be sure to always check that your response variable is coded correctly before modeling.\n\n\nNext, we will fit a binary logistic regression model using the `glm()` function in R. The syntax is similar to that of the `lm()` function, but we need to specify the `family` argument as `binomial` to indicate that we are performing logistic regression. Here, we will model the probability of developing coronary heart disease based on age.\n\n\n::: {.cell}\n```{webr}\nlogistic_model <- glm(TenYearCHD ~ age, data = framingham, family = binomial)\n```\n:::\n\n\nYou can still use the `summary()` function to view the results of the model fit:\n\n\n::: {.cell}\n```{webr}\nsummary(logistic_model)\n```\n:::\n\n\nMuch of the regression output looks the same as in linear regression, but there are some key differences. The main differences are:\n\n- The test statistic is no labeled `z value` instead of `t value`.\n- A `Null deviance` and `Residual deviance` are reported instead of `Multiple R-squared` and `Adjusted R-squared`.\n\n\n## Making predictions\n\nWe can also use R to calculate the predicted probabilities from our fitted logistic regression model using the `predict()` function. Below is an example where we are calculating the predicted probability that a 50-year old develops CHD in the next ten years:\n\n\n::: {.cell}\n```{webr}\npredict(logistic_model, newdata = data.frame(age = 50), type = \"response\")\n```\n:::\n\n\nNotice that we are specifying the data (x values) use for prediction using the same argument as in linear regression: we create a data frame with columns named identically to the actual data set used to fit the mode. We also must specify `type = \"response\"` to get probabilities. If you omit this argument, you will get a prediction on the log-odds scale, which isn't a probability!\n\n\n## Inference for single regression coefficients\n\nYou have already seen that we can obtain Wald-based tests via the `summary()` command. To extract only that coefficient table, you can use the `tidy()` command from the broom package:\n\n\n::: {.cell}\n```{webr}\nlibrary(broom)\ntidy(logistic_model)\n```\n:::\n\n\nTo calculate Wald-based confidence intervals for each regression coefficient, we can use the `confint()` command, specifying the `level` argument:\n\n\n::: {.cell}\n```{webr}\ntidy(logistic_model, conf.int = TRUE, conf.level = 0.9)\n```\n:::\n\n\n\n***\n\n## Function quick reference\n\nThe following table summarizes the functions discussed above:\n\n| Function | Purpose |\n|----|-----------|\n| `glm(formula, data, family = binomial)` | Fit a binary logistic regression model |\n| `summary(model)` | View model summary and Wald tests |\n| `predict(model, newdata, type = \"response\")` | Make predictions on the probability scale |\n| `tidy(model, conf.int = TRUE, conf.level)` | Extract coefficient table with confidence intervals |\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}