{
  "hash": "fb4324617119cd6f44046a48ddc7d038",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Including Categorical Predictors\"\nwebr:\n  packages:\n    - ggeffects\n    - ggformula\nformat: \n  live-html:\n    toc: true\nengine: knitr\neditor: source\neditor_options: \n  chunk_output_type: console\n---\n\n\n::: {.cell}\n\n:::\n\n\n\n\n\n\n## Overview\n\nIn this activity you will learn how to include build multiple regression models in R, including models with categorical predictors. The `cars` data set loaded below contains information on used cars for sale, including their `Price`, `Mileage`, and `Make` (a categorical variable with six levels).\n \n\n::: {.cell}\n```{webr}\ncars <- read.csv(\"https://aloy.github.io/stat230-materials/data/Cars.csv\", stringsAsFactors = TRUE)\n```\n:::\n\n\n## Thinking about the data\n\nTo begin, create a scatterplot of `Price` versus `Mileage`. \n\n\n::: {.cell min-lines='3'}\n```{webr}\n#| min-lines: 3\n# put your code here\n```\n:::\n\n\n**Q1.** What do you notice about the relationship between these two variables? Is a transformation necessary?\n\n**Q2.** The `Make` variable is categorical with six levels: Buick, Cadillac, Chevrolet, Pontiac, SAAB, and Saturn. To include this variable in a regression model, we need use indicator (i.e., dummy) variables. How many do we need to make?\n\n\n\n## Fitting an MLR model\n\nBuild (fit) a multiple regression model using `log(Price)` as the response with `Mileage` and `Make` as the predictor variables. To do this, you use `+` to separate the predictor variable on the right side of the `~` in the model formula. R will automatically convert a categorical explanatory variable into a set of indicator variables. \n\n\n::: {.cell}\n```{webr}\n# Fill in the blanks to fit the MLR model\ncar_lm <- lm(___ ~ ___ + ___, data = ___)\nsummary(car_lm)\n```\n:::\n\n\n**Q3.** Report the fitted regression equation and the $R^2$ value. \n\n**Q4.**Which level of `Make` is the baseline? The baseline level is represented by 0's across all of the indicator variables and won't have a coefficient in the output.\n\n\n**Q5.**What strategy did R use to create the indicator variables for `Make`? In other words, how did R decide which level of `Make` to use as the baseline?\n\n\n**Q6.** Which of the following models best describes the one just fit: parallel lines, different slopes, or separate lines?\n\n\n## Plotting the fitted model\n\nTo plot a fitted regression model, we can use the `ggpredict()` and `plot()` functions in the {ggeffects} package. The `ggpredict()` function creates a data frame of predicted values from the model for each `Make` across a range of `Mileage` values. The `plot()` function then creates a plot of these predicted values.\n\n\n::: {.cell}\n```{webr}\n# Be sure to load ggeffects!\nlibrary(ggeffects)\n\n# First, make predictions from the model\n# Fill in the blank with your model name\ncars_pred <- ggpredict(___, terms = ~Mileage + Make)\n\n# Now plot the predictions\nplot(cars_pred)\n```\n:::\n\n\n**Q7.** Does this plot confirm your answer to the previous question?\n\n:::{.callout-note}\n# Tips on plotting the model\n\n## Holding other variables at \"typical\" values\nIf you have more predictor variables in your model, then variables not specified in the `terms` argument the `ggpredict()` function are set to a specific value. Quantitative variables are set to their mean. Categorical variables are set to the mode (the level with the most observations).\n\n## Labels\nIf you need to adjust your axis labels or title, then you will need to add a `labs()` layer to your plot. For example,\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(cars_pred) +\n  labs(x = \"My new x label\", y = \"My new y label\",\n       title = \"My new title\")\n```\n:::\n\n\n:::\n\n\n\n## Fitting a model with interactions\n\nIf we believe that the association between `Price` and `Mileage` differs by `Make`, then we can include an interaction term in our model. To do this, we use `*` instead of `+` to separate the predictor variables on the right side of the `~` in the model formula. This will include both main effects and the interaction term.\n\n\n::: {.cell}\n```{webr}\n# Fill in the blanks to fit the MLR model with interaction\ncar_lm2 <- lm(___ ~ ___ * ___, data = ___)\nsummary(car_lm2)\n```\n:::\n\n\n**Q8.** Report the fitted regression equation for Buicks and Cadillacs.\n\n**Q9.** What is the $R^2$ value for this model? Does this model appear to fit the data better than the previous model?\n\n\n## Plotting the fitted model with interactions\n\nTo plot the interaction model, we again use the `ggpredict()` and `plot()` functions in the {ggeffects} package.\n\n\n::: {.cell}\n```{webr}\n# Fill in the blank with your model name\ncars_pred2 <- ggpredict(___, terms = ~Mileage + Make)\n\n# Now plot the predictions\nplot(cars_pred2)\n```\n:::\n\n\n\n\n\n## Calculating CIs for linear combinations\n\nTo calculate a confidence interval for a linear combination of coefficients, we must first calculate the estimate and standard error of the linear combination. \n\nLet's calculate a 95% confidence interval for the slope of the Cadillac model. Refer to your notes/slides and determine the formulas for the estimate and standard error of this slope.\n\nNow that you know the formulas, you'll use R to implement them.  First, extract the coefficients and covariance matrix from the model object. Try printing the results to see what they look like and make note of where the Cadillac coefficients are located.\n\n\n::: {.cell}\n```{webr}\ncar_coefs <- coef(car_lm2) #<1>\ncar_vcov <- vcov(car_lm2)  #<2>\n```\n:::\n\n\n1. Extract the coefficients from the model object and store them in `car_coefs`.\n2. Extract the covariance matrix from the model object and store it in `car_vcov`.\n\nNext, calculate the estimate of the slope for Cadillacs.\n\n\n::: {.cell}\n```{webr}\nestimate <- car_coefs[2] + car_coefs[8] #<3>\nestimate\n```\n:::\n\n\n3. `car_coefs` is a vector, so we pull off the necessary coefficients using their position in square brackets. Here, `car_coefs[2]` pulls off the coefficient for `Mileage` and `car_coefs[8]` pulls off the coefficient for the interaction term `Mileage:MakeCadillac`. \n\nNow, calculate the standard error of the slope for Cadillacs. \n\n\n::: {.cell}\n```{webr}\nse <- sqrt(car_vcov[2,2] + car_vcov[8,8] + 2*car_vcov[2,8]) #<4>\nse\n```\n:::\n\n\n4. `car_vcov` is a matrix, so we pull off the necessary variances and covariances using their row and column positions in square brackets. Here, `car_vcov[2,2]` pulls off the variance for `Mileage`, `car_vcov[8,8]` pulls off the variance for the interaction term `Mileage:MakeCadillac`, and `car_vcov[2,8]` pulls off the covariance between these two coefficients.\n\nFinally, use the estimate and standard error to calculate a 95% confidence interval for the slope of the Cadillac model. You can use the `qt()` function to find the appropriate critical value.\n\n**Q10.** Calculate a 95% confidence interval for the slope of the Cadillac model.\n\n\n::: {.cell min-lines='3'}\n```{webr}\n#| min-lines: 3\n# Calculate the 95% CI here\n```\n:::\n\n\n\n## Calculating extra sums of squares F-tests\n\nDo we really need the interaction terms? To answer this question, we can use an extra sums of squares F-test to compare the model with interaction terms to the model without interaction terms.\n\nWe have already seen how to use the `anova()` function to compare two nested models. Here, we will use it again to compare our two car models.\n\n\n::: {.cell}\n```{webr}\n# Fill in the blanks to run the extra sums of squares F-test\nanova(___, ___)\n```\n:::\n\n\n### Using only the full model\n\nWe can also calculate the extra sums of squares F-test using only the full model. To do this, we need to extract the SSE and degrees of freedom for both models from the ANOVA table for the full model. \n\n**Q11.** Run the below code and verify that the df, sums of squares, mean squares, F value, and p-value match what you got from the previous `anova()` command.\n\n\n::: {.cell}\n```{webr}\nanova(car_lm2)\n```\n:::\n\n\n\n\n\n***\n\n## Function quick reference\n\nThe following table summarizes the functions we learned today:\n\n| Function | Purpose |\n|----|-----------|\n| `lm()` | Fit a linear model |\n| `summary()` | Display detailed results from a fitted model |\n| `coef()` | Extract model coefficients |\n| `vcov()` | Extract the variance-covariance matrix of model coefficients |\n| `ggpredict()` | Create a data frame of predicted values from a fitted model |\n| `plot()` | Create a plot of predicted values from a fitted model |\n| `anova()` | Create an ANOVA table for a fitted model or compare two nested models |\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}