{
  "hash": "b492b6286ff19b66095aaf929c1cdbb7",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Modeling Binomial Counts\"\nsubtitle: \"Logistic regression -- Stat 230\"\nformat: \n  revealjs:\n    chalkboard: \n      buttons: false\neditor: source\n---\n\n\n\n\n## Moth coloration data {.smaller}\n\n\n- J. A. Bishop studied how natural selection worked on moths in England. Trees near Liverpool England were blackened by air pollution from the mills (1970’s).\n\n- 7 locations chosen, progressively farther from Liverpool\n\n- At each location, 8 trees were chosen at random and equal number of light and dark moths were glued on the trees \n\n- After 24 hours, the number of moths taken (presumably by birds) were counted for each morph\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> Morph </th>\n   <th style=\"text-align:right;\"> Distance </th>\n   <th style=\"text-align:right;\"> Placed </th>\n   <th style=\"text-align:right;\"> Removed </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> light </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 17 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dark </td>\n   <td style=\"text-align:right;\"> 0.0 </td>\n   <td style=\"text-align:right;\"> 56 </td>\n   <td style=\"text-align:right;\"> 14 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> light </td>\n   <td style=\"text-align:right;\"> 7.2 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 28 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> dark </td>\n   <td style=\"text-align:right;\"> 7.2 </td>\n   <td style=\"text-align:right;\"> 80 </td>\n   <td style=\"text-align:right;\"> 20 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.footer style=\"text-align: left; margin-left: 50px\"}\nExample adapted from *The Statistical Sleuth*\n:::\n## [Moth Coloration and Natural Selection]{style=\"color:#FFFFFF\"} {background-image=\"http://catherinephamevolution.weebly.com/uploads/4/9/7/3/49739619/189059_orig.jpg\" background-size=\"cover\" background-position=\"bottom\" style=\"color: \"}\n\n\n. . .\n\n<br>\n\n::: r-stack\n:::{style=\"background: #FFFFFF; width: 1000px; height: 300px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\n- Is the proportion of moths removed different between the light and dark trees?\n\n- Does this proportion depend on distance?\n:::\n:::\n:::\n\n\n\n\n## Binomial response\n\n\n- $Y_i =$ the number of moths removed (i.e. successes) on each tree, in each morph\n\n. . .\n\n- $Y_i =$ sum of $n_i$ success/failure (Bernoulli) trials\n\n. . .\n\n- We will **assume** that these trials are independent\n\n. . .\n\n::: r-stack\n:::{style=\"background: #B7CFDC; width: 1000px; height: 300px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\n**Binomial distribution**\n\nThe sum of independent and identically distributed success/failure trials follows a Binomial(n, p) distribution.\n:::\n:::\n:::\n\n\n## Binomial logistic regression {.smaller}\n\n\n**Goal:** Model $\\pi_i = {\\rm P}(\\text{success} | x_{1i}, x_{2i}, \\ldots, x_{pi})$\n\n. . .\n\n<br>\n\n::: r-stack\n:::{style=\"background: #B7CFDC; width: 1000px; height: 150px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\n${\\rm logit}(\\pi_i) = \\log\\left( \\dfrac{\\pi_i}{1- \\pi_i} \\right) = \\beta_0 + \\beta_1 x_{1i} +  \\cdots + \\beta_p x_{pi} = \\eta_i$\n:::\n:::\n:::\n\n. . .\n\n<br>\n\n::: r-stack\n:::{style=\"background: #D9E4EC; width: 1000px; height: 150px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\n$\\pi_i = \\dfrac{e^{\\eta_i}}{1 + e^{\\eta_i}}= \\dfrac{e^{\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_p x_{pi}}}{1 + e^{\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_p x_{pi}}}$\n:::\n:::\n:::\n\n\n\n<!-- $Y_i | x_1, \\ldots, x_p \\sim {\\rm Binom}(n_i, \\pi_i)$ -->\n\n\n<!-- Thus, -->\n\n<!-- - $\\mu(Y_i | x_1, \\ldots, x_p) = m_i \\pi(X_i)$, where  -->\n\n<!--     $\\pi(X_i) = \\dfrac{\\exp(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_p x_{pi})}{1 + \\exp(\\beta_0 + \\beta_1 x_{1i} + \\beta_2 x_{2i} + \\cdots + \\beta_p x_{pi})}$ -->\n\n<!-- - ${\\rm Var}(Y_i | x_1, \\ldots, x_p) = m_i \\pi(X_i) (1 - \\pi(X_i))$ -->\n\n\n\n## EDA before modeling\n\n\nThe binomial logistic regression model **assumes** that the **logit is linearly related to the predictors**\n\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-logistic-binomial_files/figure-revealjs/unnamed-chunk-2-1.png){fig-align='center' width=700}\n:::\n:::\n\n\n\n\n## Fitted model\n\n\n\\begin{aligned}\n\\log\\left( \\dfrac{\\widehat{\\pi}_i}{1- \\widehat{\\pi}_i} \\right) = −1.289 + 0.0185 {\\tt distance}_i + 0.415 {\\tt morph}_i\\\\ − 0.0277 {\\tt distance}_i \\times {\\tt morph}_i\n\\end{aligned}\n\n. . .\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](17-logistic-binomial_files/figure-revealjs/unnamed-chunk-3-1.png){fig-align='center' width=700}\n:::\n:::\n\n\n::: {.footer style=\"text-align: left; margin-left: 50px\"}\n`morph = 1` for light and `0` for dark moths \n:::\n\n## Interpretations\n\n::: r-stack\n:::{style=\"background: #B7CFDC; width: 1000px; height: 175px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\nWe interpret the fitted model just like we did in binary logistic regression!\n:::\n:::\n:::\n\n\n\\begin{aligned}\n\\log\\left( \\dfrac{\\widehat{\\pi}_i}{1- \\widehat{\\pi}_i} \\right) = −1.289 + 0.0185 {\\tt distance}_i + 0.415 {\\tt morph}_i\\\\ − 0.0277 {\\tt distance}_i \\times {\\tt morph}_i\n\\end{aligned}\n\n\n. . .\n\n\nFor dark moths, a 1 km increase in the distance from Liverpool is associated with about a 2% increase ($e^{0.0185} \\approx 1.02$ factor increase) in the odds of being taken.\n\n\n::: {.footer style=\"text-align: left; margin-left: 50px\"}\n`morph = 1` for light and `0` for dark moths \n:::\n\n## Inference\n\n::: r-stack\n:::{style=\"background: #B7CFDC; width: 1000px; height: 175px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\nWe conduct inference for binomial logistic regression using the same tools as for binary logistic regression!\n:::\n:::\n:::\n\n. . .\n\n::: {.r-fit-text}\n\n::: {.cell}\n::: {.cell-output-display}\n`````{=html}\n<table>\n <thead>\n  <tr>\n   <th style=\"text-align:left;\"> term </th>\n   <th style=\"text-align:right;\"> estimate </th>\n   <th style=\"text-align:right;\"> std.error </th>\n   <th style=\"text-align:right;\"> statistic </th>\n   <th style=\"text-align:right;\"> p.value </th>\n   <th style=\"text-align:right;\"> conf.low </th>\n   <th style=\"text-align:right;\"> conf.high </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> -1.129 </td>\n   <td style=\"text-align:right;\"> 0.198 </td>\n   <td style=\"text-align:right;\"> -5.705 </td>\n   <td style=\"text-align:right;\"> 0.000 </td>\n   <td style=\"text-align:right;\"> -1.527 </td>\n   <td style=\"text-align:right;\"> -0.750 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Distance </td>\n   <td style=\"text-align:right;\"> 0.019 </td>\n   <td style=\"text-align:right;\"> 0.006 </td>\n   <td style=\"text-align:right;\"> 3.277 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n   <td style=\"text-align:right;\"> 0.008 </td>\n   <td style=\"text-align:right;\"> 0.030 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Morphlight </td>\n   <td style=\"text-align:right;\"> 0.411 </td>\n   <td style=\"text-align:right;\"> 0.274 </td>\n   <td style=\"text-align:right;\"> 1.498 </td>\n   <td style=\"text-align:right;\"> 0.134 </td>\n   <td style=\"text-align:right;\"> -0.126 </td>\n   <td style=\"text-align:right;\"> 0.952 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> Distance:Morphlight </td>\n   <td style=\"text-align:right;\"> -0.028 </td>\n   <td style=\"text-align:right;\"> 0.008 </td>\n   <td style=\"text-align:right;\"> -3.437 </td>\n   <td style=\"text-align:right;\"> 0.001 </td>\n   <td style=\"text-align:right;\"> -0.044 </td>\n   <td style=\"text-align:right;\"> -0.012 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n:::\n\n\n- Wald tests and intervals for individual regression coefficients\n\n. . .\n\n- Drop-in deviance tests for sets of regression coefficients\n\n\n## Model assumptions\n\n- **Binomial counts**\n\n- **Independence**: observations are independent\n\n- **Linearity**: the log odds is a linear function of the predictors\n\n- **Variance structure**: the variance of a binomial random variable is $n \\pi (1 - \\pi)$\n\n    $\\Longrightarrow$ so the variance of $Y_i$ is $n_i \\pi_i (1 - \\pi_i)$ (not constant!)\n\n\n## Pearson residuals\n\n::: r-stack\n:::{style=\"background: #B7CFDC; border-radius: 10px; \"}\n:::{style=\"margin: 50px;\"}\n${\\rm Pres}_i = \\dfrac{Y_i - n_i \\widehat{\\pi}_i}{\\sqrt{n_i \\widehat{\\pi}_i (1 - \\widehat{\\pi}_i)}}$\n:::\n:::\n:::\n\nFor large enough $n_i$, Pearson residuals tend to behave like they come from $N(0,1)$\n\n. . .\n\n::: r-stack\n:::{style=\"background: #D9E4EC; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\nHow to use?\n\n- Plot against fitted values, predictors\n\n- Check for curvature, outliers\n:::\n:::\n:::\n\n\n## Pearson residuals\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-logistic-binomial_files/figure-revealjs/unnamed-chunk-5-1.png){width=775}\n:::\n:::\n\n\n- Evidence of a nonlinear relationship between the log odds and distance\n\n- No obvious outliers\n\n\n## Deviance residuals\n\n::: r-stack\n:::{style=\"background: #B7CFDC; width: 1000px; height: 175px; border-radius: 10px;\"}\n:::{style=\"margin: 50px;\"}\n::: {.r-fit-text}\n${\\rm Dres}_i = {\\rm sign}(Y_i - n_i \\widehat{\\pi}_i) \\sqrt{2 \\left[ Y_i \\log \\left( \\dfrac{Y_i}{n_i \\widehat{\\pi}_i} \\right) + (n_i - Y_i) \\log \\left( \\frac{n_i - Y_i}{n_i - n_i \\widehat{\\pi}_i} \\right) \\right]}$\n:::\n:::\n:::\n:::\n\nFor large enough $n_i$, deviance residuals tend to behave like they come from $N(0,1)$\n\n. . .\n\n::: r-stack\n:::{style=\"background: #D9E4EC;  border-radius: 10px\"}\n:::{style=\"margin: 50px;\"}\nHow to use?\n\n- Plot against fitted values, predictors\n\n- Check for curvature, outliers\n:::\n:::\n:::\n\n\n\n\n## Deviance residuals\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](17-logistic-binomial_files/figure-revealjs/unnamed-chunk-6-1.png){width=775}\n:::\n:::\n\n\n- Evidence of a nonlinear relationship between the log odds and distance\n\n- No obvious outliers\n\n\n## Drop-in deviance test\n\n\nDo we need a quadratic term for distance?\n\n\\begin{align*}\n{\\rm H_0}: &  {\\rm logit}(\\pi_i)  = \\beta_0 + \\beta_1 {\\tt dist} + \\beta_2 {\\tt morph} + \\beta_3 {\\tt dist} \\times {\\tt morph}\\\\\n{\\rm H_a}: & {\\rm logit}(\\pi_i)  = \\beta_0 + \\beta_1 {\\tt dist} + \\beta_2 {\\tt morph} + \\beta_3 {\\tt dist} \\times {\\tt morph} \\\\ & \\qquad \\qquad + \\beta_4 {\\tt dist}^2 + \\beta_45 {\\tt dist}^2 \\times {\\tt morph}\n\\end{align*}\n\n\n::: {.cell}\n\n:::\n\n\n<br>\n\nReduced model deviance = 13.2299\n\nFull model deviance = 12.7283\n\n<br>\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pchisq(0.5016, df = 2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 0.778178\n```\n\n\n:::\n:::\n\n\n\n\n\n\n\n<!-- ## Goodness-of-fit test -->\n\n\n<!-- Deviance can be used to assess the binomial logistic regression -->\n\n<!-- Observed | Predicted | True -->\n<!-- :---------:|:---------:|:---------: -->\n<!-- $Y_i$ | $\\widehat{\\pi}_i$ | $\\pi_i$ -->\n\n\n<!-- <br> -->\n\n\n\n<!-- **Deviance:** $D = 2 \\sum \\left[ Y_i \\log \\left( \\dfrac{Y_i}{m_i\\widehat{\\pi}_i} \\right)  + (m_i - Y_i)  \\log \\left( \\dfrac{m_i - Y_i}{m_i - m_i \\widehat{\\pi}_i} \\right) \\right]$ -->\n\n<!-- $D \\overset{\\cdot}{\\sim} \\chi^2$ with $\\text{d.f.}= n-(p+1)$, **if**s the model is correct and all $m_i$ are large enough (>5) -->\n\n\n<!-- $n =$ \\# of binomial observations (\\# of proportions, not # of moths) -->\n\n\n\n\n\n\n<!-- ## Goodness-of-fit test -->\n\n<!-- <div style=\"float: right; clear: right; margin: 10px;\">(the model is adequate)</div> -->\n\n<!-- H<sub>0</sub>: ${\\rm logit}(\\pi_i) = \\beta_0 + \\beta_1 x_{1i} + \\cdots + \\beta_p x_{pi}$ -->\n\n<!-- <div style=\"float: right; clear: right; margin: 10px;\">(the model is inadequate)</div> -->\n\n<!-- H<sub>a</sub>: ${\\rm logit}(\\pi_i) = \\alpha_i$ -->\n\n\n<!-- ```{r eval=FALSE} -->\n<!-- summary(moth_glm) -->\n<!-- ``` -->\n<!-- ``` -->\n<!-- Call: -->\n<!-- glm(formula = Removed/Placed ~ Distance * Morph,  -->\n<!--     family = binomial, data = case2102, weights = Placed) -->\n\n<!--     Null deviance: 35.385  on 13  degrees of freedom -->\n<!-- *Residual deviance: 13.230  on 10  degrees of freedom -->\n<!-- ``` -->\n\n<!-- ```{r} -->\n<!-- 1- pchisq(13.230, 10) -->\n<!-- ``` -->\n\n\n<!-- :::{.aside} -->\n<!-- Note: This test is *only valid for the binomial logistic regression*, it is not valid for binary logistic regression. -->\n<!-- ::: -->\n\n\n\n\n\n\n\n\n\n\n",
    "supporting": [
      "17-logistic-binomial_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\n<script>\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\n  // slide changes (different for each slide format).\n  (function () {\n    // dispatch for htmlwidgets\n    function fireSlideEnter() {\n      const event = window.document.createEvent(\"Event\");\n      event.initEvent(\"slideenter\", true, true);\n      window.document.dispatchEvent(event);\n    }\n\n    function fireSlideChanged(previousSlide, currentSlide) {\n      fireSlideEnter();\n\n      // dispatch for shiny\n      if (window.jQuery) {\n        if (previousSlide) {\n          window.jQuery(previousSlide).trigger(\"hidden\");\n        }\n        if (currentSlide) {\n          window.jQuery(currentSlide).trigger(\"shown\");\n        }\n      }\n    }\n\n    // hookup for slidy\n    if (window.w3c_slidy) {\n      window.w3c_slidy.add_observer(function (slide_num) {\n        // slide_num starts at position 1\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\n      });\n    }\n\n  })();\n</script>\n\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}